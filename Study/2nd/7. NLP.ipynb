{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ceb431-b585-4af0-9d9a-4fcdd9a1a8f8",
   "metadata": {},
   "source": [
    "# NLP(Natural Language Processing)\n",
    ": NLP is the field of making computers understand our words.\n",
    "To understand our words to computers, we can use three techniques.\n",
    "\n",
    "- Technique using thesaurus\n",
    "- A statistical-based technique\n",
    "- Word2vec\n",
    "\n",
    "## Thesaurus\n",
    ": Thesaurus is a synonym dictionary, in which synonyms are classified into a group.\n",
    "So, thesaurus can convey the meaning of a word to a computer, even indirectly.\n",
    "However, thesaurus has big flaws. The difficulty in responding to the changes of the times, the high cost of using people, and the inability to express subtle differences in words are the typical flaws of thesaurus.\n",
    "\n",
    "## A statistical-based technique\n",
    ": A statistical-based technique's goal is to abstract its core efficiently and automatically from the corpus(말뭉치).\n",
    "The corpus is the text data for NFL research or application, not just collected text data.\n",
    "\n",
    "1. Preprocessing corpus <br>\n",
    "   This process is making small text corpora from sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97d77dc3-28db-49c7-b7e8-d2c143327bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # convert all texts to small letters\n",
    "    text = text.replace('.', ' .')\n",
    "    words = text.split(' ') # split by space\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in words:\n",
    "        if word not in word_to_id:\n",
    "            new_id = len(word_to_id) # length of dictionary is set up to new word's ID\n",
    "            word_to_id[word] = new_id\n",
    "            id_to_word[new_id] = word # if there are no words or ID, add them\n",
    "\n",
    "        corpus = np.array([word_to_id[w] for w in words]) \n",
    "\n",
    "        return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245f1208-5e7a-4889-b7db-d1291d417e91",
   "metadata": {},
   "source": [
    "2. Co-occurrence matrix(동시발생행렬) <br>\n",
    "   * Distributional representation(분산표현) : To express words to vector so that create easy and reasonable vector expression on domain of words\n",
    "   * Distributional hypothesis(본포가설) : The meaning of words are created by surrounding words <br>\n",
    "     * Contexts are the words around a particular word\n",
    "     * Context size = window size (윈도우 크기가 2이면 좌우 두 단어씩 맥락에 포함)\n",
    "\n",
    "    Before making co-occurence matrix, start preprocessing by using corpora and preprocess function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f531932-7450-41af-8498-dbc1852c975b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n",
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)\n",
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfca4c3-dfcc-454d-8004-955c99127084",
   "metadata": {},
   "source": [
    "Count the frequency of the word that corresponds to the context of each word. (set window size to 1 and start from \"you\" which the ID is 0)<br>\n",
    "The following is a manual implementation of the co-occurrence matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7195c0-0d33-4148-8070-3473bedc6de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n",
      "[0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "C = np.array([\n",
    "    [0, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0],\n",
    "], dtype=np.int32) # Co-occurrence matrix\n",
    "\n",
    "print(C[0])\n",
    "print(C[4])\n",
    "print(C[word_to_id['goodbye']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d7ff9-5a08-43e8-aa55-3992db2ad000",
   "metadata": {},
   "source": [
    "The following is a function that create co-occurence matrix automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225573e5-4f00-4e74-9c8f-8e2acdd33b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_co_matrix(corpus, vocab_size, window_size=1):\n",
    "    corpus_size = len(corpus)\n",
    "    co_matrix = np.zeros((vocab_size, vocab_size), dtype=np.int32) # initialize to 2 dimension matrix filled with 0\n",
    "\n",
    "    for idx, word_id in enumerate(corpus): #bring ID and word by using enumerate\n",
    "        for i in range(1, window_size + 1):\n",
    "            left_idx = idx - i\n",
    "            right_idx = idx + i\n",
    "\n",
    "            if left_idx >= 0:\n",
    "                left_word_id = corpus[left_idx]\n",
    "                co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "            if right_idx < corpus_size:\n",
    "                right_word_id = corpus[right_idx]\n",
    "                co_matrix[word_id, right_word_id] += 1\n",
    "\n",
    "    return co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be77c7-0278-4885-bc00-a633ddfc8ddb",
   "metadata": {},
   "source": [
    "3. Vector similarity <br>\n",
    "   To estimate vector similarity, we can use vector dot product or Euclidean distance. But for word vector similarity, cosine similarity is usually used. The following fomular is definition of cosine similarity, when two verctors ($ x = (x_{1}, x_{2}, \\cdot\\cdot\\cdot, x_{n}), y = (y_{1}, y_{2}, \\cdot\\cdot\\cdot, y_{n}) $) are existed.\n",
    "   $$ similarity(x, y) = \\frac{x\\cdot y}{\\left\\|x \\right\\|\\left\\|y \\right\\|} = \\frac{x_{1}y_{1} + \\cdot\\cdot\\cdot + x_{n}y_{n}}{\\sqrt{x_{1}^{2}+ \\cdot\\cdot\\cdot + x_{n}^{2}} \\sqrt{y_{1}^{2}+ \\cdot\\cdot\\cdot + y_{n}^{2}}} $$\n",
    "   Cosine similarity is how similar are two vectors's direction. Cosine similarity's value will be 1 when two vectors's directions are same, while it's value will be -1 when two vectors's directions are opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1393bcda-6baf-4ba3-80eb-c895bbc47324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y, eps=1e-8): # to prevent divide by zero by using eps(epsilon)\n",
    "    nx = x / (np.sqrt(np.sum(x ** 2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y ** 2)) + eps)\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e5575-7954-4a18-917b-c3fff1141356",
   "metadata": {},
   "source": [
    "The following code is finding a similarity of \"you\" and \"i(=I)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82b749e3-cae4-452b-be73-7aa221bda743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067691154799\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]\n",
    "print(cos_similarity(c0, c1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96117364-3121-4f1f-92d4-57ba889f4423",
   "metadata": {},
   "source": [
    "4. Show rank of similar words <br>\n",
    "   The following function has a function of outputting words similar to the query(검색아) in the order of similarity when a word is given as a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7967d682-168d-47a7-ac5f-5d368f6e5475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(query, word_to_id, id_to_word, word_matrix, top=5):\n",
    "    # Bring out query\n",
    "    if query not in word_to_id:\n",
    "        print('%s(을)를 찾을 수 없습니다.' % query)\n",
    "        return\n",
    "\n",
    "    print('\\n[query] ' + query)\n",
    "    query_id = word_to_id[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "\n",
    "    # Caculate cosine similarity\n",
    "    vocab_size = len(id_to_word)\n",
    "    similarity = np.zeros(vocab_size)\n",
    "    for i in range(vocab_size):\n",
    "        similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "\n",
    "    # Outputs in descending order based on cosine similarity\n",
    "    count = 0\n",
    "    for i in (-1 * similarity).argsort():\n",
    "        if id_to_word[i] == query:\n",
    "            continue\n",
    "        print(' %s: %s' % (id_to_word[i], similarity[i]))\n",
    "\n",
    "        count += 1\n",
    "        if count >= top:\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35aa7eff-7158-4c80-bb38-7aa82aa9d4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067691154799\n",
      " i: 0.7071067691154799\n",
      " hello: 0.7071067691154799\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess, create_co_matrix, most_similar\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "most_similar('you', word_to_id, id_to_word, C, top=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a62bcf-bd15-4282-a6af-137d24d12257",
   "metadata": {},
   "source": [
    "## Improvement of a statistical-based technique\n",
    "\n",
    "1. Mutual information <br>\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29711218-c1bd-4dfc-aec3-96d455bbfa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(C, verbose=False, eps=1e-8):\n",
    "    M = np.zeros_like(C, dtype=np.float32)\n",
    "    N = np.sum(C)\n",
    "    S = np.sum(C, axis=0)\n",
    "    total = C.shape[0] * C.shape[1]\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(C.shape[0]):\n",
    "        for j in range(C.shape[1]):\n",
    "            pmi = np.log2(C[i, j] * N / (S[j]*S[i]) + eps)\n",
    "            M[i, j] = max(0, pmi)\n",
    "\n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % (total//100 + 1) == 0:\n",
    "                    print('%.1f%% 완료' % (100*cnt/total))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51d06c9-3570-4982-a3ca-7de57e762265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 행렬\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import preprocess, create_co_matrix, cos_similarity, ppmi\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(word_to_id)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "print('동시발생 행렬')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36b17cb-3c69-4fc4-b8c2-7eb81b0b84f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      "[-3.409e-01 -1.110e-16 -4.441e-16  1.205e-01  9.323e-01  0.000e+00\n",
      "  3.207e-16]\n",
      "[-3.409e-01 -1.110e-16]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from common.util import preprocess, create_co_matrix, ppmi\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(id_to_word)\n",
    "C = create_co_matrix(corpus, vocab_size, window_size=1)\n",
    "W = ppmi(C)\n",
    "\n",
    "U, S, V = np.linalg.svd(W)\n",
    "\n",
    "print(C[0])\n",
    "print(W[0])\n",
    "print(U[0])\n",
    "\n",
    "print(U[0, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b200e80-a32b-4c71-aaf0-55087fbcd974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "말뭉치 크기: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print('말뭉치 크기:', len(corpus))\n",
    "print('corpus[:30]:', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e4067e-7b90-42c3-952e-35feb7eddab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n",
      "1.0% done\n",
      "2.0% done\n",
      "3.0% done\n",
      "4.0% done\n",
      "5.0% done\n",
      "6.0% done\n",
      "7.0% done\n",
      "8.0% done\n",
      "9.0% done\n",
      "10.0% done\n",
      "11.0% done\n",
      "12.0% done\n",
      "13.0% done\n",
      "14.0% done\n",
      "15.0% done\n",
      "16.0% done\n",
      "17.0% done\n",
      "18.0% done\n",
      "19.0% done\n",
      "20.0% done\n",
      "21.0% done\n",
      "22.0% done\n",
      "23.0% done\n",
      "24.0% done\n",
      "25.0% done\n",
      "26.0% done\n",
      "27.0% done\n",
      "28.0% done\n",
      "29.0% done\n",
      "30.0% done\n",
      "31.0% done\n",
      "32.0% done\n",
      "33.0% done\n",
      "34.0% done\n",
      "35.0% done\n",
      "36.0% done\n",
      "37.0% done\n",
      "38.0% done\n",
      "39.0% done\n",
      "40.0% done\n",
      "41.0% done\n",
      "42.0% done\n",
      "43.0% done\n",
      "44.0% done\n",
      "45.0% done\n",
      "46.0% done\n",
      "47.0% done\n",
      "48.0% done\n",
      "49.0% done\n",
      "50.0% done\n",
      "51.0% done\n",
      "52.0% done\n",
      "53.0% done\n",
      "54.0% done\n",
      "55.0% done\n",
      "56.0% done\n",
      "57.0% done\n",
      "58.0% done\n",
      "59.0% done\n",
      "60.0% done\n",
      "61.0% done\n",
      "62.0% done\n",
      "63.0% done\n",
      "64.0% done\n",
      "65.0% done\n",
      "66.0% done\n",
      "67.0% done\n",
      "68.0% done\n",
      "69.0% done\n",
      "70.0% done\n",
      "71.0% done\n",
      "72.0% done\n",
      "73.0% done\n",
      "74.0% done\n",
      "75.0% done\n",
      "76.0% done\n",
      "77.0% done\n",
      "78.0% done\n",
      "79.0% done\n",
      "80.0% done\n",
      "81.0% done\n",
      "82.0% done\n",
      "83.0% done\n",
      "84.0% done\n",
      "85.0% done\n",
      "86.0% done\n",
      "87.0% done\n",
      "88.0% done\n",
      "89.0% done\n",
      "90.0% done\n",
      "91.0% done\n",
      "92.0% done\n",
      "93.0% done\n",
      "94.0% done\n",
      "95.0% done\n",
      "96.0% done\n",
      "97.0% done\n",
      "98.0% done\n",
      "99.0% done\n",
      "SVD 계산 ...\n",
      "\n",
      "[query] you\n",
      " i: 0.7042312622070312\n",
      " we: 0.6380184292793274\n",
      " do: 0.5555058121681213\n",
      " someone: 0.5100798606872559\n",
      " 'd: 0.49354541301727295\n",
      "\n",
      "[query] year\n",
      " month: 0.690078616142273\n",
      " quarter: 0.6445268392562866\n",
      " earlier: 0.6124014854431152\n",
      " last: 0.6123822927474976\n",
      " june: 0.5763775110244751\n",
      "\n",
      "[query] car\n",
      " auto: 0.5962799191474915\n",
      " truck: 0.5655069947242737\n",
      " luxury: 0.5516599416732788\n",
      " vehicle: 0.5126134157180786\n",
      " corsica: 0.4293666481971741\n",
      "\n",
      "[query] toyota\n",
      " motor: 0.7575503587722778\n",
      " nissan: 0.6677231192588806\n",
      " motors: 0.6519284844398499\n",
      " honda: 0.6321029663085938\n",
      " mazda: 0.5975488424301147\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.util import most_similar, create_co_matrix, ppmi\n",
    "from dataset import ptb\n",
    "\n",
    "window_size = 2\n",
    "wordvec_size = 100\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산 ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C, verbose=True)\n",
    "\n",
    "print('SVD 계산 ...')\n",
    "try:\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components=wordvec_size, n_iter=5, random_state=None)\n",
    "except ImportError:\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "\n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126966e-5f17-4070-8306-7570bbc04dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
