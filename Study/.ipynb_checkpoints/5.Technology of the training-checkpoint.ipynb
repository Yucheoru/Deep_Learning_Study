{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a90c21c-f00d-431c-be50-d794997c1a85",
   "metadata": {},
   "source": [
    "# SGD\n",
    "\n",
    "SGD is the simple way to find the optimal parameters by using the gradient of the parameters.\n",
    "The following equation means a simple equation that goes only a certain distance in the inclined direction.\n",
    "$$W{\\leftarrow}W-\\eta \\frac{\\partial L}{\\partial W}$$ ($W$ = weights, $\\eta$ = learning rate, $\\frac{\\partial L}{\\partial W}$ = gradient of loss function to $W$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9edca6f0-5dec-4c87-9423-2b7c0ef0fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc9e0f-3924-40c8-8da0-628648119dc8",
   "metadata": {},
   "source": [
    "## \bshortcoming of SGD\n",
    "\n",
    "In SGD, the search path is inefficient in anisotropic function(비등방성 함수) (a function in which the point indicated by the gradient at a specific coordinate(좌표) may change). Momentum, AdaGrad, and Adam are three ways to improve this shortcoming.\n",
    "\n",
    "# Momentum\n",
    "\n",
    "Momentum uses the rate of change of the parameter updated by the combination of the current gradient and the momentum accumulated in the previous stage. \n",
    "Simply put, the momentum adjusts the parameter in a better direction in the current stage, supported by the direction of parameter update in the previous stage. \n",
    "For example, a ball appears to roll on the bottom of the bowl.\n",
    "$$v{\\leftarrow}av-\\eta \\frac{\\partial L}{\\partial W}$$\n",
    "$$W{\\leftarrow}W+v$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6449e4b8-87f5-496a-a011-5aea282c7a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "\n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key, val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "\n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]\n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c71cd-8a8d-4669-806b-969d700ded97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53297b81-1fb8-4ddd-8cd0-762a6ef949f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
